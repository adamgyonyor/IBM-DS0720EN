{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_csv(\"SpaceX_ML_Predict_X.csv\")\n",
    "df_y = pd.read_csv(\"SpaceX_ML_Predict_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138, 93), (138, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.shape, df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train Split:\t110\n",
      "Size of Test Split:\t28\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Train Split:\\t{:.0f}\".format(np.round(df_X.shape[0]*(1-0.2))))\n",
    "print(\"Size of Test Split:\\t{:.0f}\".format(df_X.shape[0] - np.round(df_X.shape[0]*(1-0.2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_seeds = np.append(np.random.randint(0, 100, 20), np.linspace(100, 119, 20))\n",
    "random_seeds.sort()\n",
    "random_seeds = random_seeds.astype('int')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.bar(x=np.linspace(0, 39, 40), height=random_seeds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = [\"Logistic Regression\", \"Support Vector Machine\", \"Decision Tree\", \"K-Nearest Neighbors\"]\n",
    "features = [\"All\", \"Selected\"]\n",
    "folds = [\"Train\", \"Test\"]\n",
    "cols2 = []\n",
    "cols3 = []\n",
    "\n",
    "for clas in classifiers:\n",
    "    for feat in features:\n",
    "        cols2.append((clas, feat))\n",
    "            \n",
    "for clas in classifiers:\n",
    "    for feat in features:\n",
    "        for fold in folds:\n",
    "            cols3.append((clas, feat, fold))\n",
    "            \n",
    "cols2 = pd.MultiIndex.from_tuples(cols2)\n",
    "cols3 = pd.MultiIndex.from_tuples(cols3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rs = pd.DataFrame(index=random_seeds, columns=cols3)\n",
    "df_trn_id = pd.DataFrame(index=random_seeds, columns=np.arange(np.round(df_X.shape[0]*(1-0.2))))\n",
    "df_tst_id = pd.DataFrame(index=random_seeds, columns=np.arange(df_X.shape[0] - np.round(df_X.shape[0]*(1-0.2))))\n",
    "df_bp = pd.DataFrame(index=random_seeds, columns=cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rs in enumerate(random_seeds):\n",
    "    \n",
    "# Train Test Split\n",
    "    df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=rs)\n",
    "    X_train = df_X_train.to_numpy()\n",
    "    X_test = df_X_test.to_numpy()\n",
    "    y_train = df_y_train.to_numpy().ravel()\n",
    "    y_test = df_y_test.to_numpy().ravel()\n",
    "    \n",
    "# Indices of Train and Test Splits\n",
    "    for j in range(df_trn_id.shape[1]):\n",
    "        df_trn_id.iloc[i,j] = df_X_train.index[j]\n",
    "    for j in range(df_tst_id.shape[1]):\n",
    "        df_tst_id.iloc[i,j] = df_X_test.index[j]\n",
    "        \n",
    "# Logistic Regression - All Features\n",
    "    pipe_lr_all = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                            (\"lr\", LogisticRegression())])\n",
    "    param_lr_all ={\"lr__C\":[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                   'lr__penalty':['l2'],\n",
    "                   'lr__solver':['lbfgs']}\n",
    "    grid_lr_all = GridSearchCV(pipe_lr_all,\n",
    "                               param_grid=param_lr_all,\n",
    "                               cv=10,\n",
    "                               n_jobs=3)\n",
    "    grid_lr_all.fit(X_train, y_train)\n",
    "    cv_score_lr_all = grid_lr_all.best_score_\n",
    "    score_lr_all = grid_lr_all.score(X_test, y_test)\n",
    "    df_rs.iloc[i,0] = cv_score_lr_all\n",
    "    df_rs.iloc[i,1] = score_lr_all\n",
    "    df_bp.iloc[i,0] = str(grid_lr_all.best_params_)\n",
    "    \n",
    "# Support Vector Machine - All Features\n",
    "    pipe_svm_all = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                             (\"svm\", SVC())])\n",
    "    param_svm_all = {'svm__kernel':['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                     'svm__C': np.logspace(-3, 3, 5),\n",
    "                     'svm__gamma':np.logspace(-3, 2, 6)}\n",
    "    grid_svm_all = GridSearchCV(pipe_svm_all,\n",
    "                                param_grid=param_svm_all,\n",
    "                                cv=10,\n",
    "                                n_jobs=3)\n",
    "    grid_svm_all.fit(X_train, y_train)\n",
    "    cv_score_svm_all = grid_svm_all.best_score_\n",
    "    score_svm_all = grid_svm_all.score(X_test, y_test)\n",
    "    df_rs.iloc[i,4] = cv_score_svm_all\n",
    "    df_rs.iloc[i,5] = score_svm_all\n",
    "    df_bp.iloc[i,2] = str(grid_svm_all.best_params_)\n",
    "    \n",
    "# Decision Tree - All Features\n",
    "    pipe_dt_all = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                            (\"dt\", DecisionTreeClassifier())])\n",
    "    param_dt_all = {'dt__criterion': ['gini', 'entropy'],\n",
    "                    'dt__splitter': ['best', 'random'],\n",
    "                    'dt__max_depth': [2*n for n in range(1,10)],\n",
    "                    'dt__max_features': ['auto', 'sqrt'],\n",
    "                    'dt__min_samples_leaf': [1, 2, 4],\n",
    "                    'dt__min_samples_split': [2, 5, 10]}\n",
    "    grid_dt_all = GridSearchCV(pipe_dt_all,\n",
    "                               param_grid=param_dt_all,\n",
    "                               cv=10,\n",
    "                               n_jobs=3)\n",
    "    grid_dt_all.fit(X_train, y_train)\n",
    "    cv_score_dt_all = grid_dt_all.best_score_\n",
    "    score_dt_all = grid_dt_all.score(X_test, y_test)\n",
    "    df_rs.iloc[i,8] = cv_score_dt_all\n",
    "    df_rs.iloc[i,9] = score_dt_all\n",
    "    df_bp.iloc[i,4] = str(grid_dt_all.best_params_)\n",
    "    \n",
    "# K-Nearest Neighbors - All Features\n",
    "    pipe_knn_all = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                             (\"knn\", KNeighborsClassifier())])\n",
    "    param_knn_all = {'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                     'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                     'knn__p': [1,2]}\n",
    "    grid_knn_all = GridSearchCV(pipe_knn_all,\n",
    "                                param_grid=param_knn_all,\n",
    "                                cv=10,\n",
    "                                n_jobs=3)\n",
    "    grid_knn_all.fit(X_train, y_train)\n",
    "    cv_score_knn_all = grid_knn_all.best_score_\n",
    "    score_knn_all = grid_knn_all.score(X_test, y_test)\n",
    "    df_rs.iloc[i,12] = cv_score_knn_all\n",
    "    df_rs.iloc[i,13] = score_knn_all\n",
    "    df_bp.iloc[i,6] = str(grid_knn_all.best_params_)\n",
    "    \n",
    "# Logistic Regression - Selected Features\n",
    "    pipe_lr_selected = Pipeline([(\"selector\", SelectKBest()),\n",
    "                                 (\"scaler\", StandardScaler()),\n",
    "                                 (\"lr\", LogisticRegression())])\n",
    "    param_lr_selected ={'selector__score_func':[f_classif],\n",
    "                        'selector__k':[10],\n",
    "                        \"lr__C\":[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                        'lr__penalty':['l2'],\n",
    "                        'lr__solver':['lbfgs']}\n",
    "    grid_lr_selected = GridSearchCV(pipe_lr_selected,\n",
    "                                    param_grid=param_lr_selected,\n",
    "                                    cv=10,\n",
    "                                    n_jobs=3)\n",
    "    grid_lr_selected.fit(X_train, y_train)\n",
    "    cv_score_lr_selected = grid_lr_selected.best_score_\n",
    "    score_lr_selected = grid_lr_selected.score(X_test, y_test)\n",
    "    df_rs.iloc[i,2] = cv_score_lr_selected\n",
    "    df_rs.iloc[i,3] = score_lr_selected\n",
    "    df_bp.iloc[i,1] = str(grid_lr_selected.best_params_)\n",
    "\n",
    "# Support Vector Machine - Selected Features\n",
    "    pipe_svm_selected = Pipeline([(\"selector\", SelectKBest()),\n",
    "                                  (\"scaler\", StandardScaler()),\n",
    "                                  (\"svm\", SVC())])\n",
    "    param_svm_selected = {'selector__score_func':[f_classif],\n",
    "                          'selector__k':[10],\n",
    "                          'svm__kernel':['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                          'svm__C': np.logspace(-3, 3, 5),\n",
    "                          'svm__gamma':np.logspace(-3, 2, 6)}\n",
    "    grid_svm_selected = GridSearchCV(pipe_svm_selected,\n",
    "                                     param_grid=param_svm_selected,\n",
    "                                     cv=10,\n",
    "                                     n_jobs=3)\n",
    "    grid_svm_selected.fit(X_train, y_train)\n",
    "    cv_score_svm_selected = grid_svm_selected.best_score_\n",
    "    score_svm_selected = grid_svm_selected.score(X_test, y_test)\n",
    "    df_rs.iloc[i,6] = cv_score_svm_selected\n",
    "    df_rs.iloc[i,7] = score_svm_selected\n",
    "    df_bp.iloc[i,3] = str(grid_svm_selected.best_params_)\n",
    "    \n",
    "# Decision Tree - Selected Features\n",
    "    pipe_dt_selected = Pipeline([(\"selector\", SelectKBest()),\n",
    "                                 (\"scaler\", StandardScaler()),\n",
    "                                 (\"dt\", DecisionTreeClassifier())])\n",
    "    param_dt_selected = {'selector__score_func':[f_classif],\n",
    "                         'selector__k':[10],\n",
    "                         'dt__criterion': ['gini', 'entropy'],\n",
    "                         'dt__splitter': ['best', 'random'],\n",
    "                         'dt__max_depth': [2*n for n in range(1,10)],\n",
    "                         'dt__max_features': ['auto', 'sqrt'],\n",
    "                         'dt__min_samples_leaf': [1, 2, 4],\n",
    "                         'dt__min_samples_split': [2, 5, 10]}\n",
    "    grid_dt_selected = GridSearchCV(pipe_dt_selected,\n",
    "                                    param_grid=param_dt_selected,\n",
    "                                    cv=10,\n",
    "                                    n_jobs=3)\n",
    "    grid_dt_selected.fit(X_train, y_train)\n",
    "    cv_score_dt_selected = grid_dt_selected.best_score_\n",
    "    score_dt_selected = grid_dt_selected.score(X_test, y_test)\n",
    "    df_rs.iloc[i,10] = cv_score_dt_selected\n",
    "    df_rs.iloc[i,11] = score_dt_selected\n",
    "    df_bp.iloc[i,5] = str(grid_dt_selected.best_params_)\n",
    "\n",
    "# K-Nearest Neighbors - Selected Features\n",
    "    pipe_knn_selected = Pipeline([(\"selector\", SelectKBest()),\n",
    "                                  (\"scaler\", StandardScaler()),\n",
    "                                  (\"knn\", KNeighborsClassifier())])\n",
    "    param_knn_selected = {'selector__score_func':[f_classif],\n",
    "                          'selector__k':[10],\n",
    "                          'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                          'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                          'knn__p': [1,2]}\n",
    "    grid_knn_selected = GridSearchCV(pipe_knn_selected,\n",
    "                                     param_grid=param_knn_selected,\n",
    "                                     cv=10,\n",
    "                                     n_jobs=3)\n",
    "    grid_knn_selected.fit(X_train, y_train)\n",
    "    cv_score_knn_selected = grid_knn_selected.best_score_\n",
    "    score_knn_selected = grid_knn_selected.score(X_test, y_test)\n",
    "    df_rs.iloc[i,14] = cv_score_knn_selected\n",
    "    df_rs.iloc[i,15] = score_knn_selected\n",
    "    df_bp.iloc[i,7] = str(grid_knn_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"SpaceX_ML_Predict_Random_Seeds.xlsx\") as writer:\n",
    "    df_rs.to_excel(writer, sheet_name=\"Accuracies\", index_label=\"Random Seed\")\n",
    "    df_trn_id.to_excel(writer, sheet_name=\"Train Split Indices\", index_label=\"Random Seed\")\n",
    "    df_tst_id.to_excel(writer, sheet_name=\"Test_Split Indices\", index_label=\"Random Seed\")\n",
    "    df_bp.to_excel(writer, sheet_name=\"Best Parameters\", index_label=\"Random Seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
